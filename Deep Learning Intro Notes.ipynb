{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7658d5-ef39-46df-a30d-a815e7fbe664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Preprocessing tools\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# Deep learning tols\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ba012-19c8-4115-bb35-6d495e9e61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from your path\n",
    "df = pd.read_csv(\"cancer.csv\", index_col=0)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f5029-43b2-46f5-818d-2e4af3df2264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "df.isna().sum().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78d64e2-5b95-474a-80c4-a893ddbd45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "target = 'diagnosis'\n",
    "X = df.drop(columns = target)\n",
    "y = df[target]\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ec663-3772-4822-9fe5-645647f62f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to numbers\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "y_train_enc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440953bf-01b8-4d24-b0f1-9758dae6495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert encoded target values to a series\n",
    "y_train_enc = pd.Series(le.transform(y_train), index=y_train.index,\n",
    "             name=target)\n",
    "y_test_enc = pd.Series(le.transform(y_test), index=y_test.index,\n",
    "             name=target)\n",
    "y_train_enc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70364544-79a0-4860-97cc-aa689815c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class balance\n",
    "y_train_enc.value_counts(normalize = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c069a89-cd5a-45f2-929e-7c8bd9d33be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_tf = scaler.transform(X_train)\n",
    "X_test_tf = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b557edd3-6a77-4441-b466-5e252f97b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define our network structure\n",
    "# Save the number of features we have as our input shape\n",
    "input_shape = X_train_tf.shape[1]\n",
    "input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a109564f-be0d-45da-a231-43555644e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "model = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b77d24-b0ef-4102-995b-5f4a63936108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First hidden layer\n",
    "model.add(Dense(30, # How many neurons you have in your first hidden layer\n",
    "                input_dim = input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "# Second hidden layer\n",
    "model.add(Dense(10, # How many neurons you have in your second hidden layer\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9ca2a0-6b6b-4544-be72-3973b6214b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f3273-a6a6-48fc-8860-76728969d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7335b7bd-cf30-455f-a381-b10cd31ce4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Compile\n",
    "model.compile(loss = 'bce', optimizer = 'adam',)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e57b31-38c8-4114-9d8b-fbc9020313f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing the model summary before training\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef5e76-eb51-4a63-b10d-c310d7cbe52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fit our model\n",
    "history = model.fit(X_train_tf, y_train_enc,\n",
    "                    validation_data = (X_test_tf, y_test_enc), \n",
    "                    epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15891f8-feab-4481-8dc5-b12110d97116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History.history is a dictionary\n",
    "history.history.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a96ba5-b960-4383-b727-3e2ec78e3fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric value for every training epoch\n",
    "history.history['loss']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f49af-e064-456b-bdc5-29f51801b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.history['loss'], label='Train loss', marker='o')\n",
    "ax.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "ax.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe45198-6bb4-4641-b9a9-6ffbfcaa0f37",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8172939a-81da-4d37-bdc7-5044e13acced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "model.add(Dense(30, # How many neurons you have in your first hidden layer\n",
    "                input_dim = input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "# Second hidden layer\n",
    "model.add(Dense(10, # How many neurons you have in your second hidden layer\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "# Output layer\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a05e2b-7bbc-402a-a58a-3d2b69d9dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics are specified during the .compile step\n",
    "# Step 2: Compile\n",
    "model.compile(loss = 'bce', optimizer = 'adam'\n",
    "              , metrics=['accuracy',\n",
    "                         tf.keras.metrics.Recall(name='recall'),\n",
    "                         tf.keras.metrics.Precision(name='precision'),\n",
    "                        ])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19629ab-a52e-445f-b58e-c36ddea2297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fit our model\n",
    "history = model.fit(X_train_tf, y_train_enc,\n",
    "                    validation_data = (X_test_tf, y_test_enc), \n",
    "                    epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5589849a-299b-4e4e-ab39-01a9c1fcd35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the history to a dataframe for readability\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f046d-c07e-4fd7-83df-8d00a9d89201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for plotting each metric\n",
    "def plot_history(history, figsize=(6,12), marker='o'):\n",
    "       \n",
    "    # Get list of metrics from history\n",
    "    metrics = [c for c in history.history if not c.startswith('val_')]\n",
    "    \n",
    "    ## Separate row for each metric\n",
    "    fig, axes = plt.subplots(nrows=len(metrics),figsize=figsize)\n",
    "    \n",
    "    # For each metric\n",
    "    for i, metric_name in enumerate(metrics):\n",
    "    \n",
    "        # Get the axis for the current metric\n",
    "        ax = axes[i]\n",
    "    \n",
    "        # Get metric from history.history\n",
    "        metric_values = history.history[metric_name]\n",
    "        # Get epochs from history\n",
    "        epochs = history.epoch\n",
    "    \n",
    "        # Plot the training metric\n",
    "        ax.plot(epochs, metric_values, label=metric_name, marker=marker)\n",
    "    \n",
    "        ## Check if val_{metric} exists. if so, plot:\n",
    "        val_metric_name = f\"val_{metric_name}\"\n",
    "        if val_metric_name in history.history:\n",
    "            # Get validation values and plot\n",
    "            metric_values = history.history[val_metric_name]\n",
    "            ax.plot(epochs,metric_values,label=val_metric_name, marker=marker)\n",
    "    \n",
    "        # Final subplot adjustments \n",
    "        ax.legend()\n",
    "        ax.set_title(metric_name)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, axes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd123ea4-9093-40e2-a5c5-81137fe084e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the custom function\n",
    "plot_history(history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28433517-25e8-40a1-a991-3704c1e544f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "model.add(Dense(30, # How many neurons you have in your first hidden layer\n",
    "                input_dim = input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "# Second hidden layer\n",
    "model.add(Dense(10, # How many neurons you have in your second hidden layer\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "# Output layer\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "### Metrics are specified during the.compile step\n",
    "# Step 2: Compile\n",
    "model.compile(loss = 'bce', optimizer = 'adam'\n",
    "              , metrics=['accuracy',\n",
    "                         tf.keras.metrics.Recall(name='recall'),\n",
    "                         tf.keras.metrics.Precision(name='precision'),\n",
    "                        ])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6fcb98-e382-4cc7-a710-c1b8704ba768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fit our model\n",
    "history = model.fit(X_train_tf, y_train_enc,\n",
    "                    validation_split=.2, \n",
    "                    epochs=10)\n",
    "\n",
    "plot_history(history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08a6a2-4cd2-440d-b3c6-da27d6fd45f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate neural network with builtin evaluation\n",
    "result = model.evaluate(X_test_tf, y_test_enc,return_dict=True)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc3ca5d-eb2b-4094-9786-445d06f86bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_test = model.predict(X_test_tf)\n",
    "y_pred_test[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae112da-fbce-40b4-9a5b-501f5d5dd843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the predictions\n",
    "y_pred_test = np.round(y_pred_test)\n",
    "y_pred_test[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591fda1-76ba-4b21-b2d0-a47f5f46e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,ConfusionMatrixDisplay\n",
    "print(classification_report(y_test_enc, y_pred_test))\n",
    " \n",
    "ConfusionMatrixDisplay.from_predictions(y_test_enc, y_pred_test, cmap='Blues',\n",
    "                                       normalize='true');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a407c-6d45-475f-b4ce-6399fbbb92c9",
   "metadata": {},
   "source": [
    "# Bias and Variance in Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc02546-fb6f-4781-856e-141dc4736c48",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d8356-933b-462f-aae6-ae9b950f385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3a2f2-2170-4d50-b88b-5126ca09d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, figsize=(6,12), marker='o'):\n",
    "       \n",
    "    # Get list of metrics from history\n",
    "    metrics = [c for c in history.history if not c.startswith('val_')]\n",
    "    \n",
    "    ## Separate row for each metric\n",
    "    fig, axes = plt.subplots(nrows=len(metrics),figsize=figsize)\n",
    "    \n",
    "    \n",
    "    # For each metric\n",
    "    for i, metric_name in enumerate(metrics):\n",
    "        # Get the axis for the current metric\n",
    "        if len(metrics)==1:\n",
    "            ax = axes\n",
    "        else:\n",
    "            ax = axes[i]\n",
    "    \n",
    "        # Get metric from history.history\n",
    "        metric_values = history.history[metric_name]\n",
    "        # Get epochs from history\n",
    "        epochs = history.epoch\n",
    "    \n",
    "        # Plot the training metric\n",
    "        ax.plot(epochs, metric_values, label=metric_name, marker=marker)\n",
    "    \n",
    "        ## Check if val_{metric} exists. if so, plot:\n",
    "        val_metric_name = f\"val_{metric_name}\"\n",
    "        if val_metric_name in history.history:\n",
    "            # Get validation values and plot\n",
    "            metric_values = history.history[val_metric_name]\n",
    "            ax.plot(epochs,metric_values,label=val_metric_name, marker=marker)\n",
    "    \n",
    "        # Final subplot adjustments \n",
    "        ax.legend()\n",
    "        ax.set_title(metric_name)\n",
    "    fig.tight_layout()\n",
    "    return fig, axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f322e2-438a-49a9-a3b1-6064d82390c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from your path\n",
    "df = pd.read_csv('nba.csv', index_col = 'Name')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c1e39-a66b-49dd-81b8-5f0bca7d3921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "df.isna().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bcbf7b-ff99-4450-a29e-f6e4429b64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missings\n",
    "df.dropna(inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef7198-aace-4068-986a-fad6a6a07a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "target = 'TARGET_5Yrs'\n",
    "X = df.drop(columns = target)\n",
    "y = df[target]\n",
    "# Train test_Val split\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size = .3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02929ea-c769-4f64-bc12-3b1203fc7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the X_test_val into test and val data \n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size = .5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcaf38a-62e1-427c-bfbd-20ced275bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale our data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71007f2e-e499-4014-964e-b600c40cf47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define our network structure\n",
    "# Save the number of features we have as our input shape\n",
    "input_shape = X_train.shape[1]\n",
    "input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469d454-1eba-4794-a972-fd707cdc4abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without dropout\n",
    "# Sequential model\n",
    "model = Sequential()\n",
    "# First hidden layer\n",
    "model.add(Dense(19, # How many neurons you have in your first hidden layer\n",
    "                input_dim = input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "model.add(Dense(10, \n",
    "                activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'bce', optimizer = 'adam',\n",
    "              metrics=['accuracy',\n",
    "                         tf.keras.metrics.Recall(name='recall'),\n",
    "                         tf.keras.metrics.Precision(name='precision'),\n",
    "                        ])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824994e0-cf1d-4395-83fd-cd9e2a630a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data= (X_val, y_val), \n",
    "                    epochs=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e04f9-cac2-4e03-a450-72b0c0b5f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "plot_history(history, marker='.');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90cb983-35da-409c-a782-a54ebcc908e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate neural network with built in evaluation\n",
    "result = model.evaluate(X_test, y_test, return_dict=True)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b3169a-ecdc-4f72-ae28-169d8a18e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "model = Sequential()\n",
    "# First hidden layer\n",
    "model.add(Dense(19, # How many neurons you have in your first hidden layer\n",
    "                input_dim = input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "model.add(Dense(10, \n",
    "                activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'bce', optimizer = 'adam',\n",
    "             metrics=['accuracy',\n",
    "                         tf.keras.metrics.Recall(name='recall'),\n",
    "                         tf.keras.metrics.Precision(name='precision')])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val), \n",
    "                    epochs=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415597f-c3c0-49db-8aec-b1d315df7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "plot_history(history, marker='.');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6749e99e-f961-44ca-8b23-b0739518fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate neural network with built in evaluation\n",
    "result = model.evaluate(X_test, y_test, return_dict=True)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0488dc7c-9f7e-4e1d-ac36-22c442c4f7fc",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e3fd8-28e0-4676-8fab-2d0a6a8c3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c1e321-3813-46ec-88e9-9515c166a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With early stopping\n",
    "# Sequential model\n",
    "model = Sequential()\n",
    "# First hidden layer\n",
    "model.add(Dense(19, # How many neurons you have in your first hidden layer\n",
    "                input_dim =input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "model.add(Dense(10, \n",
    "                activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'bce', optimizer = 'adam',\n",
    "             metrics=['accuracy',\n",
    "                         tf.keras.metrics.Recall(name='recall'),\n",
    "                         tf.keras.metrics.Precision(name='precision')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e7c0c-b772-41cd-9823-d587b9b33141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate EarlyStopping\n",
    "early_stopping = EarlyStopping(patience = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b7fcff-1155-4d57-b363-3a09322d6aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with the early stopping callback\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data = (X_val, y_val), \n",
    "                    epochs=100,\n",
    "                    callbacks = [early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44482d-1db3-449c-a761-7e444fa7daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate neural network with built in evaluation\n",
    "result = model.evaluate(X_test, y_test, return_dict=True)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f8302-27b6-4989-a358-0097a5cce210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With dropout and early stopping\n",
    "# Sequential model\n",
    "model = Sequential()\n",
    "# First hidden layer\n",
    "model.add(Dense(19, # How many neurons you have in your first hidden layer\n",
    "                input_dim = input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "model.add(Dense(10, \n",
    "                activation = 'relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'bce', optimizer = 'adam',\n",
    "             metrics=['accuracy',\n",
    "                         tf.keras.metrics.Recall(name='recall'),\n",
    "                         tf.keras.metrics.Precision(name='precision')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7814bf2-41af-4b84-a0a0-b9f53661d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate early stopping\n",
    "early_stopping = EarlyStopping(patience = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4e9c2b-f96d-4ce9-9c32-4a6b0055de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model with the early stopping callback\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data = (X_test, y_test), \n",
    "                    epochs=100,\n",
    "                    callbacks = [early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143fdc1-d53c-4a69-90e3-7d8fdd3ebd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate neural network with built in evaluation\n",
    "result = model.evaluate(X_test, y_test, return_dict=True)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f6b9f-f026-4abd-bbbc-e65515eca5b3",
   "metadata": {},
   "source": [
    "## Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c119e1-cee4-4eae-8f76-1e6b4398d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and Compile Model within a function\n",
    "def build_model():\n",
    "    # Instantiate Model \n",
    "    model = Sequential()\n",
    "    # First hidden layer\n",
    "    model.add(Dense(19, # How many neurons you have in your first hidden layer\n",
    "                input_dim =input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "    model.add(Dense(10, \n",
    "                activation = 'relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # Compile Model\n",
    "    model.compile(loss = 'bce', optimizer = 'adam',\n",
    "             metrics=['accuracy',\n",
    "                         tf.keras.metrics.Recall(name='recall'),\n",
    "                         tf.keras.metrics.Precision(name='precision')])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b17cf4-711f-4bc7-b806-184843806b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call our build function to build model\n",
    "basic_model = build_model()\n",
    "\n",
    "# Get model summary\n",
    "basic_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a21ae3c-2a1e-40d7-9fa1-f27d74b2c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperParameters as hp\n",
    "import keras_tuner as kt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59543e33-dc2d-4585-9433-0e6643e1e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and Compile Model within a function to try optimizers\n",
    "def build_model(hp):\n",
    "    # Instantiate Model \n",
    "    model = Sequential()\n",
    "    # First hidden layer\n",
    "    model.add(Dense(19, # How many neurons you have in your first hidden layer\n",
    "                input_dim =input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "    model.add(Dense(10, \n",
    "                activation = 'relu'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # Compile Model\n",
    "    model.compile(optimizer=hp.Choice('optimizer',['rmsprop','nadam','adam']),\n",
    "                  loss='bce',\n",
    "                  metrics=['accuracy',\n",
    "                           tf.keras.metrics.Recall(name='recall'),\n",
    "                           tf.keras.metrics.Precision(name='precision')])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba8cbc-1ca1-4e60-9c8b-19108fd16260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a folder to store results of hyperparameter tuning\n",
    "import os\n",
    "folder = 'KerasTuner/'\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34b193-c5ce-4bfa-9378-548994d630e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tuner object\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=5,\n",
    "                     directory=folder,\n",
    "                     overwrite = True,\n",
    "                     seed = 42,\n",
    "                     project_name='Rookie_tuning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e25607-e0d5-4d22-ae5a-d2b74fb016ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9b5fe-ff47-44b1-8261-8519dbfbc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the tuner\n",
    "epochs = 100\n",
    "tuner.search(X_train, y_train,  epochs=epochs,\n",
    "             validation_data = (X_val, y_val), callbacks = [early_stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a851913-e89b-4024-bd4a-90b4cc82f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain best hyperparameter values\n",
    "best_hps=tuner.get_best_hyperparameters()[0]\n",
    "best_hps.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f360421-c2dc-4d0d-9859-7f993bfa502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain best model\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59db8f-f29a-436d-9723-995bcc15bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate neural network with built in evaluation\n",
    "result = best_model.evaluate(X_test, y_test, return_dict=True)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7109d31-7bb6-4617-8430-959827ee348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and Compile Model within a function to try different optimizers, units, and dropout values\n",
    "def build_model(hp):\n",
    "    # Instantiate Model \n",
    "    model = Sequential()\n",
    "    # First hidden layer\n",
    "    model.add(Dense(19, # How many neurons you have in your first hidden layer\n",
    "                input_dim =input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "    # Try different values for units\n",
    "    model.add(Dense(units=hp.Int('units', min_value=10, max_value=50, step=5), activation='relu'))\n",
    "    # Try different values for dropout rate\n",
    "    model.add(Dropout(hp.Float(name=\"dropout_value\", min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # Compile Model\n",
    "    # Try different optimizers\n",
    "    model.compile(optimizer=hp.Choice('optimizer',['rmsprop','nadam','adam']),\n",
    "                  loss='bce',\n",
    "                  metrics=['accuracy',\n",
    "                           tf.keras.metrics.Recall(name='recall'),\n",
    "                           tf.keras.metrics.Precision(name='precision')])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3ae2a-61a1-4f3e-9969-c3e3061a86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tuner object\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=100,\n",
    "                     directory=folder,\n",
    "                     overwrite = True,\n",
    "                     seed = 42,\n",
    "                     project_name='Rookie_tuning')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f48f7d-6edd-462a-807c-dcf224438c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the tuner\n",
    "epochs = 100\n",
    "tuner.search(X_train, y_train,  epochs=epochs,\n",
    "             validation_data = (X_val, y_val), callbacks = [early_stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a6bb0-339e-43bc-9ed4-fbaee3a01031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain best hyperparameter values\n",
    "best_hps=tuner.get_best_hyperparameters()[0]\n",
    "best_hps.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c709e-f893-491e-87cb-cc457fbbb269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain best model\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2adb5fa-cc2f-4e25-b8ce-1e6688167cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate neural network with tuned optimizer, units, and dropout\n",
    "result = best_model.evaluate(X_test, y_test, return_dict=True)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94485d-89c9-43de-90ab-e5ab3d1114c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect results in more detail\n",
    "tuner.results_summary(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceef4ac-9287-4ff9-b39a-73ae386b07f2",
   "metadata": {},
   "source": [
    "## Regression Models in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e92dcd-a554-4702-9ffe-da24bd006783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    " \n",
    "# Sci-kit learn\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set pandas as the default output for sklearn\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2754de-d7e2-4c1c-9374-66e0019d4019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for plotting each metric\n",
    "def plot_history(history, figsize=(6,12), marker='o'):\n",
    "       \n",
    "    # Get list of metrics from history\n",
    "    metrics = [c for c in history.history if not c.startswith('val_')]\n",
    "    \n",
    "    ## Separate row for each metric\n",
    "    fig, axes = plt.subplots(nrows=len(metrics),figsize=figsize)\n",
    "    \n",
    "    # For each metric\n",
    "    for i, metric_name in enumerate(metrics):\n",
    "    \n",
    "        # Get the axis for the current metric\n",
    "        ax = axes[i]\n",
    "    \n",
    "        # Get metric from history.history\n",
    "        metric_values = history.history[metric_name]\n",
    "        # Get epochs from history\n",
    "        epochs = history.epoch\n",
    "    \n",
    "        # Plot the training metric\n",
    "        ax.plot(epochs, metric_values, label=metric_name, marker=marker)\n",
    "    \n",
    "        ## Check if val_{metric} exists. if so, plot:\n",
    "        val_metric_name = f\"val_{metric_name}\"\n",
    "        if val_metric_name in history.history:\n",
    "            # Get validation values and plot\n",
    "            metric_values = history.history[val_metric_name]\n",
    "            ax.plot(epochs,metric_values,label=val_metric_name, marker=marker)\n",
    "    \n",
    "        # Final subplot adjustments \n",
    "        ax.legend()\n",
    "        ax.set_title(metric_name)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, axes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88221086-6ec0-4198-915b-0684df954eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    " \n",
    "reg_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTg36jLawSOgGP9hp0oJ3OYZiHMWbuGLiau-8DMjtcKNv7v9Zy_zFBQs9gZU-44GGeIyfXE2iwo26_z/pub?output=csv'\n",
    "df_reg = pd.read_csv(reg_url)\n",
    " \n",
    "# drop car name columns\n",
    "df_reg = df_reg.drop(columns='car name')\n",
    " \n",
    "df_reg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1a466-aee5-4f01-9dbc-77ca18d53347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values and duplicates\n",
    "print('missing values', df_reg.info())\n",
    "print('\\nduplicated rows', df_reg.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f083ba3-0b35-465d-bd6c-665a8639ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    " \n",
    "X = df_reg.drop(columns='mpg')\n",
    "y = df_reg['mpg']\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5d4525-7117-44ae-b52d-db10d605c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of columns for transformer\n",
    "cat_cols = ['cylinders','model year','origin']\n",
    "num_cols = X_train.columns.drop(cat_cols)\n",
    "\n",
    "# PREPROCESSING PIPELINE FOR NUMERIC DATA\n",
    "\n",
    "# instantiate preprocessors\n",
    "scaler = StandardScaler()\n",
    "# Make a numeric preprocessing pipeline\n",
    "num_pipe = make_pipeline(scaler)\n",
    "# Making a numeric tuple for ColumnTransformer\n",
    "num_tuple = ('numeric', num_pipe, num_cols)\n",
    "\n",
    "\n",
    "# PREPROCESSING PIPELINE FOR ONE-HOT-ENCODED DATA\n",
    "\n",
    "# Instantiate the individual preprocessors\n",
    "ohe_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "# Make pipeline with imputer and encoder\n",
    "ohe_pipe = make_pipeline(ohe_encoder)\n",
    "# Making a ohe_tuple for ColumnTransformer\n",
    "ohe_tuple = ('categorical', ohe_pipe, cat_cols)\n",
    "\n",
    "# Instantiate with verbose_feature_names_out=False\n",
    "col_transformer = ColumnTransformer([num_tuple, ohe_tuple],\n",
    "                                    verbose_feature_names_out=False)\n",
    "# Fit on training data\n",
    "col_transformer.fit(X_train)\n",
    "\n",
    "# Transform the training data\n",
    "X_train_tf = col_transformer.transform(X_train)\n",
    "# Transform the testing data\n",
    "X_test_tf = col_transformer.transform(X_test)\n",
    "# View the processed training data\n",
    "X_train_tf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563708ca-d96c-4880-8fc9-ac6a2d326cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define shape\n",
    "input_shape = X_train_tf.shape[1]\n",
    "input_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61109e1-4325-4356-9689-cba288e43a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build regression model within function\n",
    "def build_model():\n",
    "    # Instantiate Model \n",
    "    model = Sequential()\n",
    "    \n",
    "    # First hidden layer\n",
    "    model.add(Dense(10, # How many neurons you have in your first hidden layer\n",
    "                input_dim =input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "    model.add(Dense(10, \n",
    "                activation = 'relu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    \n",
    "    # Compile Model\n",
    "    model.compile(loss = 'mse', optimizer = 'adam',\n",
    "             metrics=[metrics.MeanAbsoluteError(), metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ed6fc8-f13c-4de7-a17d-7c06b49ffe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call our build function to build model\n",
    "reg_model = build_model()\n",
    "\n",
    "# Get model summary\n",
    "reg_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c1ee3-abe7-45b3-9b6f-997e041970aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd509aa-38ad-4612-8cc0-0de0340b34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = reg_model.fit(X_train_tf, y_train,\n",
    "                        validation_split = .2,\n",
    "                        epochs=100,\n",
    "                        verbose=0, callbacks = [early_stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5588f7-dbda-4d61-91d5-1d8ebf23c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning \n",
    "plot_history(history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed823a-6409-48c4-a0d6-5d27f986f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    " \n",
    "y_pred = reg_model.predict(X_test_tf)\n",
    " \n",
    "print(f'final RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}')\n",
    "print(f'final MAE: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'final R2: {r2_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1532bc-64ea-4df0-a697-8007c51c383f",
   "metadata": {},
   "source": [
    "## Binary Classification Models in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de726d-022b-4b69-bf9c-45d35ac0c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#Keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    " \n",
    "#Sci-kit Learn\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25816b4b-76c0-45e0-a22b-77e75951d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for plotting each metric\n",
    "def plot_history(history, figsize=(6,12), marker='o'):\n",
    "       \n",
    "    # Get list of metrics from history\n",
    "    metrics = [c for c in history.history if not c.startswith('val_')]\n",
    "    \n",
    "    ## Separate row for each metric\n",
    "    fig, axes = plt.subplots(nrows=len(metrics),figsize=figsize)\n",
    "    \n",
    "    # For each metric\n",
    "    for i, metric_name in enumerate(metrics):\n",
    "    \n",
    "        # Get the axis for the current metric\n",
    "        ax = axes[i]\n",
    "    \n",
    "        # Get metric from history.history\n",
    "        metric_values = history.history[metric_name]\n",
    "        # Get epochs from history\n",
    "        epochs = history.epoch\n",
    "    \n",
    "        # Plot the training metric\n",
    "        ax.plot(epochs, metric_values, label=metric_name, marker=marker)\n",
    "    \n",
    "        ## Check if val_{metric} exists. if so, plot:\n",
    "        val_metric_name = f\"val_{metric_name}\"\n",
    "        if val_metric_name in history.history:\n",
    "            # Get validation values and plot\n",
    "            metric_values = history.history[val_metric_name]\n",
    "            ax.plot(epochs,metric_values,label=val_metric_name, marker=marker)\n",
    "    \n",
    "        # Final subplot adjustments \n",
    "        ax.legend()\n",
    "        ax.set_title(metric_name)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, axes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eecb6a-811f-4983-9fb6-a839b57373a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classification data\n",
    "clf_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTZf6XIYPLjxmCS8BzzEot1DaW4ns7P2q1CVqnZ6qw9f-A3bkCPbXX3H9vOE2_zrGKSxy4ZMaTf7lt4/pub?output=csv'\n",
    "df_clf = pd.read_csv(clf_url)\n",
    "df_clf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee487cad-c7f6-4700-96eb-92101c838a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates and null values\n",
    "print(f'data info: {df_clf.info()}')\n",
    "print(f'\\n duplicate rows: {df_clf.duplicated().sum()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e2c661-1393-44ce-82c3-646995a380d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop id and encode diagnosis\n",
    "df_clf.drop(columns='id', inplace=True)\n",
    "df_clf['diagnosis'].replace(['M','B'],[1,0], inplace=True)\n",
    "df_clf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ba2c3-d43e-4845-a308-c5ba97a6c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check classes and balance\n",
    "df_clf['diagnosis'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70612e43-d81b-40ac-a99c-bf8a31ab14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    " \n",
    "X = df_clf.drop(columns='diagnosis')\n",
    "y = df_clf['diagnosis']\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32523e17-486d-4cec-96d6-2f7c94ad7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    " \n",
    "scaler = StandardScaler()\n",
    " \n",
    "X_train_tf = scaler.fit_transform(X_train)\n",
    "X_test_tf = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46f15b-dfd2-4873-b22e-44a4c22d3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input shape\n",
    "input_shape = X_train_tf.shape[1]\n",
    "input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8e892-0fdf-4449-ba30-1689b4e52198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build binary classification model within function\n",
    "def build_model():\n",
    "    # Instantiate Model \n",
    "    model = Sequential()\n",
    "    \n",
    "    # First hidden layer\n",
    "    model.add(Dense(10, # How many neurons you have in your first hidden layer\n",
    "                input_dim =input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "    model.add(Dense(10, \n",
    "                activation = 'relu'))\n",
    "    model.add(Dropout(.2))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    \n",
    "    # Compile Model\n",
    "    model.compile(loss = 'bce', optimizer = 'adam',\n",
    "             metrics=['accuracy', metrics.Precision(), metrics.Recall()])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78fe339-0008-4f7e-a094-111e35bc39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call our build function to build model\n",
    "clf_model = build_model()\n",
    "\n",
    "# Get model summary\n",
    "clf_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41846740-ea05-4919-92ad-2286a7bc64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d6c0c-21e1-4d20-b640-56d5ca924f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = clf_model.fit(X_train_tf, y_train,\n",
    "                        validation_split=.2,\n",
    "                        epochs=100,\n",
    "                        verbose=0, callbacks = [early_stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e3e0f-f105-4534-8e8b-80bbc4996f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning history\n",
    "plot_history(history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecafa48-f8eb-4125-9b2e-ede3d152e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred_test = clf_model.predict(X_test_tf)\n",
    "y_pred_test[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577111e5-1685-454a-a572-9ad458c98c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the predictions\n",
    "y_pred_test = np.round(y_pred_test)\n",
    "y_pred_test[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39560a2b-d18e-493f-893b-c122a72c6853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,ConfusionMatrixDisplay\n",
    "print(classification_report(y_test, y_pred_test))\n",
    " \n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_test, cmap='Blues',\n",
    "                                       normalize='true');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f22526-4c20-4b2d-ac26-aa7ea72c10d3",
   "metadata": {},
   "source": [
    "## Multiclass Classification in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2017728-a25f-4139-9005-04743d6207db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#Keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    " \n",
    "#Sci-kit Learn\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449b4a2-1b19-44c8-8fa0-36601babed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(y_true, y_pred, label='',\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False):\n",
    "    \n",
    "    # Get the classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    ## Print header and report\n",
    "    header = \"-\"*70\n",
    "    print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "    print(report)\n",
    "    \n",
    "    ## CONFUSION MATRICES SUBPLOTS\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "    \n",
    "    # create a confusion matrix  of raw counts\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=None, cmap='gist_gray', values_format=\"d\", colorbar=colorbar,\n",
    "                ax = axes[0],);\n",
    "    axes[0].set_title(\"Raw Counts\")\n",
    "    \n",
    "    # create a confusion matrix with the test data\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=normalize, cmap=cmap, values_format=\".2f\", colorbar=colorbar,\n",
    "                ax = axes[1]);\n",
    "    axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "    \n",
    "    # Adjust layout and show figure\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return dictionary of classification_report\n",
    "    if output_dict==True:\n",
    "        report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "        return report_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5bc43-0a1b-43c0-ab88-c3d03e00f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function for plotting each metric\n",
    "def plot_history(history, figsize=(6,12), marker='o'):\n",
    "       \n",
    "    # Get list of metrics from history\n",
    "    metrics = [c for c in history.history if not c.startswith('val_')]\n",
    "    \n",
    "    ## Separate row for each metric\n",
    "    fig, axes = plt.subplots(nrows=len(metrics),figsize=figsize)\n",
    "    \n",
    "    # For each metric\n",
    "    for i, metric_name in enumerate(metrics):\n",
    "    \n",
    "        # Get the axis for the current metric\n",
    "        ax = axes[i]\n",
    "    \n",
    "        # Get metric from history.history\n",
    "        metric_values = history.history[metric_name]\n",
    "        # Get epochs from history\n",
    "        epochs = history.epoch\n",
    "    \n",
    "        # Plot the training metric\n",
    "        ax.plot(epochs, metric_values, label=metric_name, marker=marker)\n",
    "    \n",
    "        ## Check if val_{metric} exists. if so, plot:\n",
    "        val_metric_name = f\"val_{metric_name}\"\n",
    "        if val_metric_name in history.history:\n",
    "            # Get validation values and plot\n",
    "            metric_values = history.history[val_metric_name]\n",
    "            ax.plot(epochs,metric_values,label=val_metric_name, marker=marker)\n",
    "    \n",
    "        # Final subplot adjustments \n",
    "        ax.legend()\n",
    "        ax.set_title(metric_name)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce00ca-c79e-4c5c-ab74-d40b77884fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "multi_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vR_I2xiiboTvyDr5-Cvvo_m7tnoT2tVnzOWUYf2xBZEhTWiWtZOyerF3c2aQeym10S8T2yHnTPnlPi2/pub?output=csv'\n",
    "df_multi = pd.read_csv(multi_url)\n",
    "df_multi.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a61b90-ceb9-4f2d-a37c-276aab5b3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates and missing data\n",
    "print(df_multi.info())\n",
    "print(f'{df_multi.duplicated().sum()} duplicate rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7904d5c-511e-4ce1-8a44-b6afc764386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count rows with missing values\n",
    "na_rows = df_multi.isna().any(axis=1).sum()\n",
    "print(f'{na_rows} rows are missing data')\n",
    "print(f'{na_rows/len(df_multi)*100:.1f}% of rows are missing data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4176d36e-5408-4449-9383-a8c32dab3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing data\n",
    "df_multi.dropna(inplace=True)\n",
    "print(df_multi.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533ec7a2-91a7-4470-9d3e-fc218c5d14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check class balance\n",
    "df_multi['Species'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29abfc-d4ce-4187-8c16-43f25a5b48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi['Species'].replace('Beam', 'Bream', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182ea6a-613e-40d6-bc1f-ffd9492a49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X = df_multi.drop(columns='Species')\n",
    "y = df_multi['Species']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08936a7-52ae-45f7-8155-92fc44825976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "scaler = StandardScaler()\n",
    " \n",
    "X_train_tf = scaler.fit_transform(X_train)\n",
    "X_test_tf = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eade5b5-e1d4-4938-ac0c-f835cbabe3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "# encode labels\n",
    "encoder = LabelEncoder()\n",
    " \n",
    "encoder.fit(y_train)\n",
    "y_train_enc = encoder.transform(y_train)\n",
    "y_test_enc = encoder.transform(y_test)\n",
    " \n",
    "# make a record of the classes, in order of the encoding, in case we want to \n",
    "# translate predictions into fish names later.\n",
    "classes = encoder.classes_\n",
    " \n",
    "# binarize labels\n",
    "binarizer = LabelBinarizer()\n",
    " \n",
    "binarizer.fit(y_train_enc)\n",
    "y_train_bin = binarizer.transform(y_train_enc)\n",
    "y_test_bin = binarizer.transform(y_test_enc)\n",
    " \n",
    "# check results\n",
    "print('Original Target')\n",
    "print(y_train.head())\n",
    " \n",
    "print('\\nEncoded Target')\n",
    "print(y_train_enc[:5])\n",
    " \n",
    "print('\\nBinarized Target')\n",
    "print(y_train_bin[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b03dc-0dbb-48b1-8d5c-d89c36288d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input shape\n",
    "input_shape = X_train_tf.shape[1]\n",
    "input_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d70d7d-bde5-4a2c-b4fd-85985e15bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of classes\n",
    "num_classes = len(classes)\n",
    "num_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448eb9a9-6ae8-4f80-b32f-d194e65049b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build multiclass classification model within function\n",
    "def build_model():\n",
    "    # Instantiate Model \n",
    "    model = Sequential()\n",
    "    \n",
    "    # First hidden layer\n",
    "    model.add(Dense(50, # How many neurons you have in your first hidden layer\n",
    "                input_dim =input_shape, # What is the shape of your input features (number of columns)\n",
    "                activation = 'relu')) # What activation function are you using?\n",
    "    model.add(Dense(50, \n",
    "                activation = 'relu'))\n",
    "    model.add(Dropout(.2))\n",
    "    #Output layer\n",
    "    model.add(Dense(num_classes, activation = 'softmax'))\n",
    "   \n",
    "    \n",
    "    # Compile Model\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',\n",
    "             metrics=['accuracy', metrics.Precision(), metrics.Recall()])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee366fd-0b41-4a6f-ab3c-a165dd6e298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call our build function to build model\n",
    "multi_model = build_model()\n",
    "\n",
    "# Get model summary\n",
    "multi_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf05b1d-97ed-4727-9a46-185ddcce1e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    " \n",
    "history = multi_model.fit(X_train_tf, y_train_bin,\n",
    "                          validation_split = .2,\n",
    "                          epochs=100,\n",
    "                          verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53198152-448b-4f58-b2a5-a907b8b0baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning history\n",
    "\n",
    "plot_history(history);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3f74c-e62c-494e-a865-61daab414648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get raw predictions\n",
    "raw_pred = multi_model.predict(X_test_tf)\n",
    " \n",
    "# display predictions and binarized true labels\n",
    "print('Raw Predictions\\n', raw_pred[:5])\n",
    "print('\\nbinarized y_test\\n', y_test_bin[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268815a-99d5-4b23-abc8-d93e259b712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions and labels into integers representing each fish class.\n",
    "y_pred = np.argmax(raw_pred, axis=1)\n",
    "y_true = np.argmax(y_test_bin, axis=1)\n",
    " \n",
    "print('integer predictions', y_pred)\n",
    "print('integer true labels', y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123e59c-3400-4dd5-8c90-79217021534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Sklearn Metrics\n",
    "classification_metrics(y_true, y_pred, label='Test Data', figsize=(10,8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f02e2-2720-4808-8b69-d0e4e5bd9c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21ae01-4763-452f-b465-d45b37009f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fc4e5-00e4-49f4-a63d-145b8ff51eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb74f082-4194-4c6e-96b5-8bdb2836375e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d46d5c-e734-480f-a675-61829a4a69e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70101d1-cf7d-428b-8a5b-408f04e9cc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a7b7d6-e4b5-4076-96b5-dfd219c7d97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8fbf3c-64f9-435d-90ee-94c16b731e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
